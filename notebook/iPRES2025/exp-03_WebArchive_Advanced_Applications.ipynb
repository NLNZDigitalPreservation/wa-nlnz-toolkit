{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c782d34d",
   "metadata": {},
   "source": [
    "# Processing Web Archive Text Corpus\n",
    "\n",
    "This notebook demonstrates how to work with text files extracted from web archive HTML snapshots. We'll cover the following steps:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Extracting text from web archive HTML\n",
    "3. Cleaning and preprocessing the text data\n",
    "4. Advanced analysis with embeddings and semantic search\n",
    "5. Building a question-answering system with the corpus\n",
    "\n",
    "**Purpose**: This notebook shows how to process and analyze text extracted from web archives, enabling researchers to gain insights from historical web content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a36034",
   "metadata": {},
   "source": [
    "## 1. Setting up the environment\n",
    "\n",
    "First, let's install the required packages for web archive processing, text analysis, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b53589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core web archive processing packages\n",
    "!pip -q install warcio>=1.7.4 validators boto3>=1.40.26 s3fs bs4 wordcloud\n",
    "\n",
    "# Install packages for web screenshots (optional)\n",
    "!pip -q install selenium chromedriver-autoinstaller\n",
    "\n",
    "# Install packages for embeddings and semantic search\n",
    "!pip -q install sentence-transformers chromadb\n",
    "\n",
    "# Install the NLNZ Web Archive Toolkit\n",
    "!pip -q install -i https://test.pypi.org/simple/ wa-nlnz-toolkit==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e91132",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a319f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment and set appropriate paths\n",
    "# This allows the notebook to run in different environments (local or Colab)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Set default result folder based on environment\n",
    "if IN_COLAB:\n",
    "    res_folder = \"/content/sample_data\"\n",
    "else:\n",
    "    res_folder = \"./sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b856e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wa_nlnz_toolkit as want\n",
    "from tqdm import tqdm  # Progress bar for long-running operations\n",
    "from glob import glob  # File pattern matching\n",
    "from collections import Counter  # For counting word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd67cfa",
   "metadata": {},
   "source": [
    "## 2. Extracting text from web archive HTML\n",
    "\n",
    "Web archives store content in WARC (Web ARChive) files. Here we demonstrate how to extract HTML content from these files and convert it to plain text using the `wa_nlnz_toolkit` library.\n",
    "\n",
    "The process involves two main steps:\n",
    "1. Extract the HTML payload from a WARC file using `extract_payload`\n",
    "2. Parse the HTML to extract meaningful text using `extract_content_html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract HTML payload from a WARC file\n",
    "# This demonstrates accessing a specific web page snapshot from an archive\n",
    "warc_file = \"s3://ndha-public-data-ap-southeast-2/iPRES-2025/sample-data/covid19.govt.nz/2023-12-14_IE89493927/FL89493929_NLNZ-20231212233435565-00000-72544~wlgprdwctweb01.natlib.govt.nz~8443.warc.gz\"\n",
    "offset = 3126252  # Byte offset where the record starts in the WARC file\n",
    "\n",
    "# Extract the HTML payload\n",
    "html_payload = want.extract_payload(warc_file, offset)\n",
    "\n",
    "# Check if extraction was successful\n",
    "if html_payload:\n",
    "    print(f\"Successfully extracted HTML payload of {len(html_payload)} bytes\")\n",
    "else:\n",
    "    print(\"Failed to extract HTML payload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab9ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text content from the HTML payload\n",
    "# This converts raw HTML into readable text paragraphs\n",
    "if html_payload:\n",
    "    # Use the toolkit's function to extract content\n",
    "    paragraphs = want.extract_content_html(html_payload)\n",
    "    \n",
    "    # Print the first few paragraphs as a sample\n",
    "    print(f\"Extracted {len(paragraphs)} paragraphs. Here are the first 5:\")\n",
    "    for i, para in enumerate(paragraphs[:5]):\n",
    "        print(f\"\\n{i+1}. {para}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225945f9",
   "metadata": {},
   "source": [
    "## 3. Cleaning and preprocessing the text data\n",
    "\n",
    "Raw text extracted from web archives often contains duplicates, irrelevant content, and formatting issues. This section demonstrates how to clean and preprocess this data to make it more suitable for analysis.\n",
    "\n",
    "The main preprocessing steps include:\n",
    "1. Loading raw text files\n",
    "2. Removing duplicates across snapshots\n",
    "3. Maintaining the relationship between content and source URLs\n",
    "4. Saving the cleaned data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc69663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for raw and cleaned data\n",
    "raw_folder_path = os.path.join(res_folder, \"covid19_corpus/raw/\")\n",
    "cleaned_folder_path = os.path.join(res_folder, \"covid19_corpus/cleaned/\")\n",
    "\n",
    "# Create directory structure for cleaned data\n",
    "# We maintain separate directories for content and URLs\n",
    "cleaned_content_dir = os.path.join(cleaned_folder_path, \"content\")\n",
    "cleaned_url_dir = os.path.join(cleaned_folder_path, \"url\")\n",
    "os.makedirs(cleaned_content_dir, exist_ok=True)\n",
    "os.makedirs(cleaned_url_dir, exist_ok=True)\n",
    "\n",
    "# List all text files in the raw folder\n",
    "raw_content_dir = os.path.join(raw_folder_path, \"content\")\n",
    "raw_url_dir = os.path.join(raw_folder_path, \"url\")\n",
    "raw_content_files = [f for f in os.listdir(raw_content_dir) if f.endswith(\".txt\")]\n",
    "print(f\"Found {len(raw_content_files)} raw text files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bdaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract date from filename\n",
    "def extract_date(fname):\n",
    "    \"\"\"Extract date in YYYY-MM-DD format from a filename.\n",
    "    \n",
    "    Args:\n",
    "        fname: Filename string containing a date\n",
    "        \n",
    "    Returns:\n",
    "        Date string in YYYY-MM-DD format or None if not found\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', fname)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ff77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all content files chronologically\n",
    "content_files = sorted(glob(os.path.join(raw_content_dir, \"covid19_content_cleaned_*.txt\")))\n",
    "seen_contents = set()  # Track unique content across all snapshots\n",
    "\n",
    "# Lists to store data for later analysis\n",
    "list_date_tag = []\n",
    "list_unique_pages = []\n",
    "\n",
    "# Process each content file and its corresponding URL file\n",
    "for content_file in content_files:\n",
    "    # Extract date from filename\n",
    "    date_tag = extract_date(os.path.basename(content_file))\n",
    "    url_file = os.path.join(raw_url_dir, f\"covid19_url_cleaned_{date_tag}.txt\")\n",
    "\n",
    "    # Skip if URL file is missing\n",
    "    if not os.path.exists(url_file):\n",
    "        print(f\"‚ö†Ô∏è URL file missing for {date_tag}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {date_tag} ...\")\n",
    "\n",
    "    # Read content and URL files\n",
    "    with open(content_file, encoding=\"utf-8\") as f:\n",
    "        contents = [line.strip() for line in f]\n",
    "\n",
    "    with open(url_file, encoding=\"utf-8\") as f:\n",
    "        urls = [line.strip() for line in f]\n",
    "\n",
    "    # Verify content and URL files have matching line counts\n",
    "    assert len(contents) == len(urls), f\"Line count mismatch in {date_tag}\"\n",
    "\n",
    "    # Filter out duplicates while preserving content-URL relationship\n",
    "    unique_contents = []\n",
    "    unique_urls = []\n",
    "\n",
    "    for content, url in zip(contents, urls):\n",
    "        if content not in seen_contents:\n",
    "            seen_contents.add(content)\n",
    "            unique_contents.append(content)\n",
    "            unique_urls.append(url)\n",
    "\n",
    "    # Save deduplicated content and URLs\n",
    "    out_content = os.path.join(cleaned_content_dir, f\"covid19_content_deduped_{date_tag}.txt\")\n",
    "    out_url = os.path.join(cleaned_url_dir, f\"covid19_url_deduped_{date_tag}.txt\")\n",
    "\n",
    "    with open(out_content, \"w\", encoding=\"utf-8\") as f:\n",
    "        for c in unique_contents:\n",
    "            f.write(c + \"\\n\")\n",
    "\n",
    "    with open(out_url, \"w\", encoding=\"utf-8\") as f:\n",
    "        for u in unique_urls:\n",
    "            f.write(u + \"\\n\")\n",
    "\n",
    "    # Store metrics for analysis\n",
    "    list_unique_pages.append(len(unique_contents))\n",
    "    list_date_tag.append(date_tag)\n",
    "\n",
    "    print(f\"‚úÖ {date_tag}: kept {len(unique_contents)} unique pages (out of {len(contents)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec97c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the number of unique pages over time\n",
    "# This helps understand how the website content evolved\n",
    "df_unique_pages = pd.DataFrame({\"date_tag\": list_date_tag, \"unique_pages\": list_unique_pages})\n",
    "df_unique_pages[\"date_tag\"] = pd.to_datetime(df_unique_pages[\"date_tag\"])\n",
    "df_unique_pages.set_index(\"date_tag\", inplace=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = df_unique_pages.plot()\n",
    "ax.set_title(\"Number of New Unique Pages Over Time\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1194a192",
   "metadata": {},
   "source": [
    "## 4. Advanced analysis with embeddings and semantic search\n",
    "\n",
    "Traditional keyword search is limited when analyzing large text corpora. Semantic search using embeddings allows us to find content based on meaning rather than exact word matches.\n",
    "\n",
    "In this section, we'll:\n",
    "1. Create vector embeddings for each text snippet\n",
    "2. Store these embeddings in a vector database (ChromaDB)\n",
    "3. Implement semantic search to find relevant content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f7517",
   "metadata": {},
   "source": [
    "First, let's import the required packages for embedding and vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cfd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import embedding and vector database libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Configuration for vector database\n",
    "db_collection_name = \"covid_webpages\"  # Name for our vector collection\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"  # Pre-trained embedding model\n",
    "path_chroma = os.path.join(res_folder, \"chroma_db\")  # Path to store the vector database\n",
    "input_content_dir = os.path.join(res_folder, \"covid19_corpus/cleaned/content\")  # Directory with cleaned text files\n",
    "input_url_dir = os.path.join(res_folder, \"covid19_corpus/cleaned/url\")  # Directory with cleaned text files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf284c87",
   "metadata": {},
   "source": [
    "ChromaDB is a vector database designed for efficient storage and retrieval of embeddings. It allows us to perform similarity searches across our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679b5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.72it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  7.15it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  6.01it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  5.87it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  7.83it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.81it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.18it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.44it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  7.07it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  7.25it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  6.96it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.62it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.88it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.54it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.29it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.69it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  6.38it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  6.36it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  6.57it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:01<00:00,  6.52it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.13it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.80it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  6.28it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  6.53it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  7.56it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  7.51it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.71it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.82it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.52it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00,  6.52it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  8.23it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  8.26it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  7.64it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 12.75it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  9.29it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.97it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.05it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.96it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.80it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.50it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.80it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexed all lines into Chroma!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB client and collection\n",
    "client = chromadb.PersistentClient(path=path_chroma)\n",
    "collection = client.get_or_create_collection(name=db_collection_name)\n",
    "\n",
    "# Load the sentence transformer model for creating embeddings\n",
    "model = SentenceTransformer(embedding_model, token=False)\n",
    "\n",
    "# Get all cleaned text files\n",
    "files = sorted([f for f in os.listdir(input_content_dir) if f.endswith(\".txt\")])\n",
    "\n",
    "# Process each file and add its contents to the vector database\n",
    "for fname in files:\n",
    "    # Load content file\n",
    "    content_file_path = os.path.join(input_content_dir, fname)\n",
    "    with open(content_file_path, encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    \n",
    "    # Load corresponding URL file\n",
    "    url_file_path = os.path.join(input_url_dir, fname.replace(\"content\", \"url\"))\n",
    "    with open(url_file_path, encoding=\"utf-8\") as f:\n",
    "        urls = [line.strip() for line in f]\n",
    "    \n",
    "    # Create embeddings for each line of text\n",
    "    # This converts text into numerical vectors that capture semantic meaning\n",
    "    embeddings = model.encode(lines, show_progress_bar=True, convert_to_numpy=True)\n",
    "    datestr = extract_date(fname)\n",
    "    \n",
    "    # Add embeddings and metadata to ChromaDB\n",
    "    try:\n",
    "        collection.add(\n",
    "            ids=[f\"{fname}_{i}\" for i in range(len(lines))],\n",
    "            embeddings=embeddings.tolist(),\n",
    "            documents=lines,\n",
    "            metadatas=[{\"filename\": fname, \"date\": datestr, \"line\": i, \"url\": url} for i, url in enumerate(urls)]\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(f\"‚ö†Ô∏è Skipped {fname} due to ValueError\")\n",
    "\n",
    "print(\"‚úÖ Indexed all lines into Chroma!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f805dd",
   "metadata": {},
   "source": [
    "Now that we have our vector database ready, we can perform semantic searches to find content based on meaning rather than exact keyword matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74a327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, n_results=5):\n",
    "    \"\"\"Perform semantic search on the corpus using vector embeddings.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query as a string\n",
    "        n_results: Number of results to return (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing search results from ChromaDB\n",
    "    \"\"\"\n",
    "    # Load the embedding model\n",
    "    model = SentenceTransformer(embedding_model)\n",
    "\n",
    "    # Connect to the vector database\n",
    "    client = chromadb.PersistentClient(path=path_chroma)\n",
    "    collection = client.get_or_create_collection(name=db_collection_name)\n",
    "\n",
    "    # Convert query to embedding vector\n",
    "    query_emb = model.encode([query], convert_to_numpy=True).tolist()\n",
    "\n",
    "    # Search for similar content in the database\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_emb,\n",
    "        n_results=n_results\n",
    "    )\n",
    "\n",
    "    # Display results with metadata\n",
    "    for text, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        print(f\"{meta['filename']} (line {meta['line']}) ‚Äî {meta['url']}\")\n",
    "        print(f\"‚Üí {text[:]}\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example semantic search query\n",
    "# This demonstrates finding content related to economic impacts without requiring exact keyword matches\n",
    "res = semantic_search(\"What is the impact of the pandemic on the economy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0965",
   "metadata": {},
   "source": [
    "## 5. Building a question-answering system with the corpus\n",
    "\n",
    "Beyond search, we can build a question-answering system that combines our vector database with language models to provide direct answers to questions about the corpus.\n",
    "\n",
    "This approach, known as Retrieval-Augmented Generation (RAG), involves:\n",
    "1. Retrieving relevant passages using semantic search\n",
    "2. Using a language model to generate answers based on the retrieved content\n",
    "\n",
    "There are usually two ways to build a QA system:\n",
    "1. Online LLM: use a language model hosted on a cloud service\n",
    "2. Offline LLM: use a language model running locally on a server\n",
    "\n",
    "In this demo, we will use the online option since it is much faster running on colab.\n",
    "\n",
    "We will use the Groq API to access the GPT-OSS-20B model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a3ea9",
   "metadata": {},
   "source": [
    "### Online LLM with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fee566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "        api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    ")  # or set in env var OPENAI_API_KEY\n",
    "\n",
    "def generate_answer_online(context, question):\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        input=prompt,\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71ffbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query_fast(query, n_results=5):\n",
    "    results = semantic_search(query, n_results=n_results)\n",
    "    context = \"\\n\\n\".join(results[\"documents\"][0])\n",
    "    answer = generate_answer_online(context, query)\n",
    "\n",
    "    print(\"\\n=== ANSWER ===\")\n",
    "    print(answer)\n",
    "    print(\"\\n=== SOURCES ===\")\n",
    "    for meta in results[\"metadatas\"][0]:\n",
    "        print(f\"- {meta['filename']} (line {meta['line']}) ‚Äî {meta['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b008d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid19_content_deduped_2022-02-15.txt (line 302) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220214032429/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "‚Üí Home Traffic lights Traffic lights map Search or browse for your local traffic light setting. --- Section Separator --- What you need to do under each traffic light setting Life at Red Life at Orange --- Section Separator --- Waka Kotahi‚Äôs Journey Planner uses the latest travel time information, traffic cameras, and updates on delays, roadworks and road closures to help you plan your journey. Use Journey Planner (external link)\n",
      "\n",
      "covid19_content_deduped_2022-04-13.txt (line 215) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220411042316/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "‚Üí Home Traffic lights Traffic lights map Search or browse for your local traffic light setting. --- Section Separator --- What you need to do under each traffic light setting Life at Red Life at Orange Life at Green --- Section Separator --- Waka Kotahi‚Äôs Journey Planner uses the latest travel time information, traffic cameras, and updates on delays, roadworks and road closures to help you plan your journey. Use Journey Planner (external link)\n",
      "\n",
      "covid19_content_deduped_2022-06-14.txt (line 161) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220613042331/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "‚Üí Home Traffic lights Traffic lights map Search or browse for your local traffic light setting. --- Section Separator --- What you need to do under each traffic light setting: Life at Red Life at Orange Life at Green --- Section Separator --- Waka Kotahi‚Äôs Journey Planner uses the latest travel time information, traffic cameras, and updates on delays, roadworks and road closures to help you plan your journey. Use Journey Planner (external link)\n",
      "\n",
      "covid19_content_deduped_2022-04-13.txt (line 172) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220411041919/https://covid19.govt.nz/traffic-lights/\n",
      "‚Üí Home Traffic lights The traffic lights (COVID-19 Protection Framework) protect Aotearoa New Zealand from COVID-19, while allowing people greater freedoms. What you need to know Events at Red Weddings at Red Playing sport at Red Visiting a rest home at Red Businesses and workplaces at Red Travel at Red Attending church at Red Education at Red --- Section Separator --- The COVID-19 Protection Framework is simpler. It will help us manage life with Omicron while reducing the impact of future outbreaks. Find out about changes to our traffic light system All of New Zealand is at the Red setting. The next review of the traffic light settings will be on Thursday 14 April 2022. --- Section Separator --- At Red, we need to take action to protect our vulnerable communities and our health system from COVID-19. Learn what we all need to do. At Orange, there will be community transmission of COVID-19, with increasing risks to vulnerable communities, and pressure on the health system. Learn what we all need to do. At Green, there is limited community transmission, and our health system is ready to respond. There are no restrictions. --- Section Separator --- At Red, we need to take action to protect our vulnerable communities and our health system from COVID-19. Learn what we all need to do. At Orange, there will be community transmission of COVID-19, with increasing risks to vulnerable communities, and pressure on the health system. Learn what we all need to do. At Green, there is limited community transmission, and our health system is ready to respond. There are no restrictions. --- Section Separator --- We have COVID-19 resources available for businesses and other organisations to download, print and share.\n",
      "\n",
      "covid19_content_deduped_2022-08-17.txt (line 120) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220815042510/https://covid19.govt.nz/traffic-lights/history-of-the-covid-19-protection-framework-traffic-lights/\n",
      "‚Üí Home Traffic lights History of the COVID-19 Protection Framework (traffic lights) --- Section Separator --- Find out what you need to do: Life at Orange Face masks at Orange The framework replaced Alert Levels in December 2021. It has 3 traffic light settings of Red, Orange and Green. The framework aims to: help people protect one another from the virus keep hospitalisation rates as low as possible and avoid overwhelming the health system minimise the impact of large outbreaks reduce the need for lockdowns. It also aims to give people and businesses more stability. At all traffic light settings, essential services will continue to operate. This includes supermarkets, health services, emergency services, goods transport, and utilities such as power and water supplies. A high vaccination rate is a key tool to protect people and minimise the spread of COVID-19. Getting vaccinated means you are less likely to get extremely sick or infect other people. Some workplaces may require staff to be vaccinated. Vaccine mandates for many government workers ended during 2022. Wearing face masks is a way we can protect ourselves and others. At Red and Orange traffic light settings, there are some places you must wear a mask, such as on public transport and in supermarkets. At Red, capacity limits apply in some indoor settings. Limits are based on 1-metre distancing, which means 1 metre square of space for each person, up to the maximum capacity limit. It does not mean everyone must stay 1 metre apart. Capacity limits do not include workers (paid and unpaid). If an area has very high infection rates, extra restrictions such as local lockdowns or other protective steps may be used. Examples of protective steps include: stay at home orders closing premises, such as schools or shops limiting numbers allowed at gatherings. COVID-19 Protection Framework traffic lights table [PDF, 57 KB] The COVID-19 Alert Level System ends. History of the Alert System At 11:59pm New Zealand moves to the COVID-19 Protection Framework, or traffic light system. Northland, Auckland, Taupo, Rotorua Lakes, Kawerau, Whakatane, ≈åp≈çtiki, Gisborne, Wairoa, Rangitikei, Whanganui, and Ruapehu districts move to Red. The rest of the North Island, and the South Island, move to Orange. Watch 1 December media conference Auckland boundary lifts at 11:59pm. People travelling out of Auckland need to be vaccinated or have proof of a negative test. First confirmed Omicron border case. The international traveller tests positive soon after arriving on 10 December. Genome sequencing then detects Omicron. Watch 16 December media conference Auckland, Taupo, Rotorua Lakes, Kawerau, Whakatane, ≈åp≈çtiki, Gisborne, Wairoa, Rangitikei, Whanganui, and Ruapehu districts move to Orange at 11:59pm. Northland remains at Red. Auckland boundary-crossing rules end. People travelling out of Auckland no longer need proof of vaccination or a negative test. Northland moves to Orange at 11:59pm. First confirmed Omicron community cases. All New Zealand moves to Red at 11:59pm. Watch 23 January media conference The Government introduces Omicron phases, with different approaches to testing and isolation as case numbers grow. Phase 1: Focus on stamping out small outbreaks, with PCR testing and 14-day isolation period for COVID-19 cases. Phase 2: Focus on slowing the spread and protecting those most at risk of getting seriously ill. Contact tracing switches to online self-assessments, isolation period drops to 10 days. Phase 3: Focus on safely managing COVID-19 at home, with self-testing kits of rapid antigen tests (RATs) and isolation only for people who test positive and their Household Contacts. Government announces 3-phase public health response to Omicron Our response to Omicron Face mask rules change for Red at 11:59pm. Increased mask use to prepare for Omicron Close Contact exemption scheme begins for workers in key sectors. All New Zealand moves to Phase 2 of the Omicron response at 11:59pm. Watch 16 February media conference All New Zealand moves to Phase 3 of the Omicron response at 11:59pm. Watch 24 February media conference Isolation period drops from 10 to 7 days at 11:59pm. Changes to traffic light settings at 11:59pm include: Indoor gathering limits at Red increase from 100 to 200 people. No more limits on numbers at outdoor gatherings in any traffic light setting. Contact tracing and record-keeping requirements end for businesses and other organisations. Vaccine passes are no longer needed in any traffic setting from 11:59pm. Most vaccine mandates end for government workers. All New Zealand remains at Red. Watch 4 April media conference All New Zealand moves to Orange at 11:59pm. Watch 13 April media conference Vaccine mandates end for border and corrections workers. Vaccine mandates end for some workers in the Defence Force, Fire and Emergency, and Police. --- Section Separator --- Find out what you need to do: Life at Orange Face masks at Orange --- Section Separator --- The framework replaced Alert Levels in December 2021. It has 3 traffic light settings of Red, Orange and Green. The framework aims to: help people protect one another from the virus keep hospitalisation rates as low as possible and avoid overwhelming the health system minimise the impact of large outbreaks reduce the need for lockdowns. It also aims to give people and businesses more stability. At all traffic light settings, essential services will continue to operate. This includes supermarkets, health services, emergency services, goods transport, and utilities such as power and water supplies. --- Section Separator --- A high vaccination rate is a key tool to protect people and minimise the spread of COVID-19. Getting vaccinated means you are less likely to get extremely sick or infect other people. Some workplaces may require staff to be vaccinated. Vaccine mandates for many government workers ended during 2022. Wearing face masks is a way we can protect ourselves and others. At Red and Orange traffic light settings, there are some places you must wear a mask, such as on public transport and in supermarkets. At Red, capacity limits apply in some indoor settings. Limits are based on 1-metre distancing, which means 1 metre square of space for each person, up to the maximum capacity limit. It does not mean everyone must stay 1 metre apart. Capacity limits do not include workers (paid and unpaid). If an area has very high infection rates, extra restrictions such as local lockdowns or other protective steps may be used. Examples of protective steps include: stay at home orders closing premises, such as schools or shops limiting numbers allowed at gatherings. COVID-19 Protection Framework traffic lights table [PDF, 57 KB] --- Section Separator --- The COVID-19 Alert Level System ends. History of the Alert System At 11:59pm New Zealand moves to the COVID-19 Protection Framework, or traffic light system. Northland, Auckland, Taupo, Rotorua Lakes, Kawerau, Whakatane, ≈åp≈çtiki, Gisborne, Wairoa, Rangitikei, Whanganui, and Ruapehu districts move to Red. The rest of the North Island, and the South Island, move to Orange. Watch 1 December media conference Auckland boundary lifts at 11:59pm. People travelling out of Auckland need to be vaccinated or have proof of a negative test. First confirmed Omicron border case. The international traveller tests positive soon after arriving on 10 December. Genome sequencing then detects Omicron. Watch 16 December media conference Auckland, Taupo, Rotorua Lakes, Kawerau, Whakatane, ≈åp≈çtiki, Gisborne, Wairoa, Rangitikei, Whanganui, and Ruapehu districts move to Orange at 11:59pm. Northland remains at Red. Auckland boundary-crossing rules end. People travelling out of Auckland no longer need proof of vaccination or a negative test. Northland moves to Orange at 11:59pm. First confirmed Omicron community cases. All New Zealand moves to Red at 11:59pm. Watch 23 January media conference The Government introduces Omicron phases, with different approaches to testing and isolation as case numbers grow. Phase 1: Focus on stamping out small outbreaks, with PCR testing and 14-day isolation period for COVID-19 cases. Phase 2: Focus on slowing the spread and protecting those most at risk of getting seriously ill. Contact tracing switches to online self-assessments, isolation period drops to 10 days. Phase 3: Focus on safely managing COVID-19 at home, with self-testing kits of rapid antigen tests (RATs) and isolation only for people who test positive and their Household Contacts. Government announces 3-phase public health response to Omicron Our response to Omicron Face mask rules change for Red at 11:59pm. Increased mask use to prepare for Omicron Close Contact exemption scheme begins for workers in key sectors. All New Zealand moves to Phase 2 of the Omicron response at 11:59pm. Watch 16 February media conference All New Zealand moves to Phase 3 of the Omicron response at 11:59pm. Watch 24 February media conference Isolation period drops from 10 to 7 days at 11:59pm. Changes to traffic light settings at 11:59pm include: Indoor gathering limits at Red increase from 100 to 200 people. No more limits on numbers at outdoor gatherings in any traffic light setting. Contact tracing and record-keeping requirements end for businesses and other organisations. Vaccine passes are no longer needed in any traffic setting from 11:59pm. Most vaccine mandates end for government workers. All New Zealand remains at Red. Watch 4 April media conference All New Zealand moves to Orange at 11:59pm. Watch 13 April media conference Vaccine mandates end for border and corrections workers. Vaccine mandates end for some workers in the Defence Force, Fire and Emergency, and Police. --- Section Separator --- Traffic lights map Life at Red Access to basic needs Life at Orange Life at Green History of the COVID-19 Protection Framework (traffic lights)\n",
      "\n",
      "\n",
      "=== ANSWER ===\n",
      "The **traffic light system** is New‚ÄØZealand‚Äôs COVID‚Äë19 Protection Framework that categorises the country‚Äôs risk level into three colours‚Äî**Red, Orange, and Green**‚Äîand ties each colour to a set of health‚Äëand‚Äëpublic‚Äësafety rules.\n",
      "\n",
      "| Colour | What it means | Typical measures |\n",
      "|--------|--------------|------------------|\n",
      "| **Red** | Highest risk of community spread and pressure on the health system. | Masks required in many indoor spaces, capacity limits (based on 1‚Äëmetre distancing), possible local lockdowns or closures of schools, shops, or gatherings; stricter testing and isolation protocols. |\n",
      "| **Orange** | Moderate‚Äëto‚Äëhigh transmission with rising risks. | Masks still mandatory in public transport and supermarkets, some limits on indoor gatherings, relaxed testing rules compared to Red, but still protective measures in place. |\n",
      "| **Green** | Low community transmission; health services are ready to respond. | No mandatory masks, no capacity limits, normal business operations, and minimal restrictions. |\n",
      "\n",
      "The system replaced the earlier ‚ÄúAlert Levels‚Äù in December‚ÄØ2021 and is designed to keep hospitalisations low, avoid overwhelming health services, limit large outbreaks, and reduce the need for lockdowns, while giving businesses and people more stability. Each colour is updated regularly by the government based on case numbers, testing, and vaccination coverage.\n",
      "\n",
      "=== SOURCES ===\n",
      "- covid19_content_deduped_2022-02-15.txt (line 302) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220214032429/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "- covid19_content_deduped_2022-04-13.txt (line 215) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220411042316/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "- covid19_content_deduped_2022-06-14.txt (line 161) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220613042331/https://covid19.govt.nz/traffic-lights/traffic-lights-map/\n",
      "- covid19_content_deduped_2022-04-13.txt (line 172) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220411041919/https://covid19.govt.nz/traffic-lights/\n",
      "- covid19_content_deduped_2022-08-17.txt (line 120) ‚Äî https://ndhadeliver.natlib.govt.nz/webarchive/20220815042510/https://covid19.govt.nz/traffic-lights/history-of-the-covid-19-protection-framework-traffic-lights/\n"
     ]
    }
   ],
   "source": [
    "rag_query_fast(\"What is the traffic light system?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2db41",
   "metadata": {},
   "source": [
    "### Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages for the QA system\n",
    "!pip -q install transformers langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5351f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for building the QA system\n",
    "from transformers import pipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b00d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the embedding model for retrieval\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Connect to the existing vector database\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=path_chroma,\n",
    "    collection_name=db_collection_name,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "# Create a retriever that will fetch relevant documents\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})  # Retrieve 5 most relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a language model for answering questions\n",
    "# We use a small open-source text generation model (flan-t5-base)\n",
    "gen_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    tokenizer=\"google/flan-t5-base\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Wrap the pipeline in a LangChain compatible format\n",
    "llm = HuggingFacePipeline(pipeline=gen_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a question-answering chain\n",
    "# This combines retrieval and generation into a single pipeline\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" concatenates retrieved docs into the prompt\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True  # Include source documents in the response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question to demonstrate the QA system\n",
    "query = \"What is the impact of the pandemic on the economy?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "# Display the question, answer, and sources\n",
    "print(\"üîπ Question:\", query)\n",
    "print(\"üîπ Answer:\", result[\"result\"])\n",
    "print(\"\\nüîπ Sources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata.get(\"filename\"), \"‚Üí\", doc.page_content[:200], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2626d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated a complete workflow for processing and analyzing text extracted from web archives:\n",
    "\n",
    "1. **Extraction**: Converting web archive HTML to plain text\n",
    "2. **Preprocessing**: Cleaning and deduplicating text data\n",
    "3. **Semantic Search**: Finding content based on meaning using vector embeddings\n",
    "4. **Question Answering**: Building an AI system that can answer questions about the corpus\n",
    "\n",
    "These techniques enable researchers to extract valuable insights from web archives, making historical web content more accessible and useful for analysis.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different embedding models for improved search quality\n",
    "- Apply topic modeling to discover themes in the corpus\n",
    "- Integrate with larger language models for more sophisticated question answering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
