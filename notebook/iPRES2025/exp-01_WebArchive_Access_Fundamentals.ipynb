{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl17JJGSkR5P"
      },
      "source": [
        "# Accessing the NLNZ Web Archive Dataset\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to access and query web archive data from the National Library of New Zealand (NLNZ). It provides a foundation for working with web archives using various protocols and APIs.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "1. Query web archive data using the Memento protocol\n",
        "2. Access archived content using the CDX API\n",
        "3. Work directly with CDX and WARC files\n",
        "4. Extract and analyze metadata from archived web content\n",
        "\n",
        "This notebook serves as an introduction to web archive access methods that will be built upon in subsequent notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlgC4Rh2ks9E"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "### Installing Required Python Packages\n",
        "\n",
        "The following packages are necessary for working with web archives:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmCJWHyxemfc"
      },
      "outputs": [],
      "source": [
        "# Install core dependencies for web archive processing\n",
        "!pip -q install warcio>=1.7.4 validators boto3>=1.40.26 s3fs bs4 wordcloud\n",
        "\n",
        "# Install packages for webpage screenshots (optional visualization)\n",
        "!pip -q install selenium chromedriver-autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFXIsPkfakpi"
      },
      "outputs": [],
      "source": [
        "# Install the NLNZ Web Archive Toolkit\n",
        "!pip -q install -i https://test.pypi.org/simple/ wa-nlnz-toolkit==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCtU0RaAevZC"
      },
      "outputs": [],
      "source": [
        "# Import the NLNZ Web Archive Toolkit\n",
        "import wa_nlnz_toolkit as want\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HJpRLC2k8Ib"
      },
      "source": [
        "## 1. Querying Web Archives with the Memento Protocol\n",
        "\n",
        "### Introduction to Memento\n",
        "\n",
        "The **Memento protocol** provides a standardized way to access archived versions of web pages across different web archives. It offers machine-readable information about web captures and simplifies the process of finding historical versions of web content.\n",
        "\n",
        "### Key Memento Components\n",
        "\n",
        "The NLNZ web archive supports three main Memento features:\n",
        "\n",
        "1. **TimeGate** - Retrieves the version of a page closest to a specified date\n",
        "2. **TimeMap** - Provides a list of all archived versions of a page\n",
        "3. **Memento** - Represents a specific archived version with options to control presentation\n",
        "\n",
        "Let's explore how to use these features with the NLNZ Web Archive Toolkit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxhCEvxA1uHw"
      },
      "source": [
        "### Basic Memento Queries\n",
        "\n",
        "We'll start by querying the latest capture of a website using the Memento protocol:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-mjPmAlokfy",
        "outputId": "5dbe127f-9d4b-4966-c3f1-096ab94fc2cf"
      },
      "outputs": [],
      "source": [
        "# Define target website\n",
        "webpage = \"www.natlib.govt.nz\"\n",
        "\n",
        "# Query the latest capture using Memento\n",
        "# This returns the raw response headers\n",
        "dict(want.query_memento(webpage).headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0o8L9zutoFV",
        "outputId": "91083279-7d60-4d83-a4e2-911c39c8fd24"
      },
      "outputs": [],
      "source": [
        "# Get a more structured representation of Memento URLs\n",
        "want.get_memento_urls(webpage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxhCEvxA1uHw"
      },
      "source": [
        "### Understanding Memento Link Types\n",
        "\n",
        "The Memento response contains several important link types:\n",
        "\n",
        "- **original**: The original URL that was archived (e.g., https://covid19.govt.nz/)\n",
        "- **timegate**: The URL used to request archived versions (e.g., https://ndhadeliver.natlib.govt.nz/webarchive/https://covid19.govt.nz/)\n",
        "- **timemap**: URL that lists all available captures (e.g., https://ndhadeliver.natlib.govt.nz/webarchive/timemap/link/https://covid19.govt.nz/)\n",
        "- **memento**: URL of the specific archived version (e.g., https://ndhadeliver.natlib.govt.nz/webarchive/20250728214105mp_/https://covid19.govt.nz/)\n",
        "\n",
        "By default, the *memento* link points to the latest capture. We can also request a capture closest to a specific date:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-70eDzh1zKN",
        "outputId": "1ed87213-9f50-43a4-e1ea-297631a79c6f"
      },
      "outputs": [],
      "source": [
        "# Query for a capture closest to January 1, 2020\n",
        "dt_required = datetime.datetime(2020, 1, 1, 0, 0, 0)\n",
        "dict(want.query_memento(webpage, dt=dt_required).headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opV6ricYfhEn",
        "outputId": "2d79330e-e756-4574-9335-178cbcc2587f"
      },
      "outputs": [],
      "source": [
        "# Get structured Memento URLs for a specific date\n",
        "want.get_memento_urls(webpage, dt=dt_required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruph4d5ng9dJ",
        "outputId": "6892c265-6c15-46b6-ae99-f8f7e9bcf5d9"
      },
      "outputs": [],
      "source": [
        "# Query another website to see its Memento links\n",
        "want.query_memento(\"www.niwa.co.nz\").links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oYPvMvN3JxV"
      },
      "source": [
        "### Retrieving Complete Capture History with TimeMap\n",
        "\n",
        "The Memento TimeMap provides a comprehensive list of all captures for a given webpage. The NLNZ web archive supports multiple TimeMap formats (link, cdxj, and json).\n",
        "\n",
        "Let's retrieve the TimeMap for our example website:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "rOiuxhrD3Kx2",
        "outputId": "dd86a068-f971-4c93-f801-df036ca9c574"
      },
      "outputs": [],
      "source": [
        "# Get the TimeMap for the National Library website\n",
        "webpage = \"www.natlib.govt.nz\"\n",
        "want.get_timemap(webpage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vFm7wmX4AjC"
      },
      "source": [
        "### URL Modifiers in Memento\n",
        "\n",
        "The `load_url` field in the TimeMap contains URLs used internally by PyWB (the web archive replay system). These cannot be directly accessed.\n",
        "\n",
        "Memento supports special URL modifiers that control how archived content is presented:\n",
        "\n",
        "- **mp_** modifier: Shows \"main page\" content only\n",
        "- **id_** modifier: Returns the original harvested version without rewriting\n",
        "- **if_** modifier: Shows the page with web archive headers (default for NLNZ web archive)\n",
        "\n",
        "For more details on URL rewriting options, see the [PyWB documentation](https://pywb.readthedocs.io/en/latest/manual/rewriter.html?highlight=id_#url-rewriting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS4hKh97lEqw"
      },
      "source": [
        "## 2. Querying Web Archives with the CDX API\n",
        "\n",
        "The CDX (Capture inDeX) API provides a more direct way to query web archive metadata. It allows for more specific filtering and returns structured data about archived captures.\n",
        "\n",
        "### Note on NLNZ Implementation\n",
        "\n",
        "In the NLNZ web archive, CDX API queries are redirected through PyWB to the OutbackCDX server. This means some native CDX query parameters (like output format) are not supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "KGE1b5DRlG4i",
        "outputId": "e4663ff5-84b6-4f37-8ac3-918717d5a0dc"
      },
      "outputs": [],
      "source": [
        "# Query the CDX index for the National Library website\n",
        "webpage = \"www.natlib.govt.nz\"\n",
        "df_captures = want.query_cdx_index(webpage)\n",
        "df_captures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CJJM3So4KRv"
      },
      "source": [
        "### CDX vs TimeMap\n",
        "\n",
        "The CDX query results are similar to the TimeMap, but our toolkit adds an `access_url` column that contains the actual URL for accessing each webpage snapshot. This makes it easier to view or analyze specific captures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced CDX Queries\n",
        "\n",
        "The CDX API allows for more specific queries, such as filtering by MIME type or using prefix matching. This is particularly useful for finding non-HTML content like images or documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query for PDF files in a specific section of a website\n",
        "# Note: Due to architecture limitations, we need to specify at least the first-level subdomain\n",
        "webpage = \"covid19.govt.nz/assets/\"\n",
        "\n",
        "# Filter for PDF files using the MIME type filter\n",
        "df_captures = want.query_cdx_index(webpage, filter=\"mimetype:application/pdf\", matchType=\"prefix\")\n",
        "\n",
        "# Extract original filenames from the URLs\n",
        "df_captures[\"original_file_name\"] = df_captures[\"urlkey\"].str.split(\"/\").str[-1]\n",
        "df_captures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hands-On Exercise: Querying for Image Files\n",
        "\n",
        "Try querying the CDX index for PNG image files from the same website section. Uncomment and complete the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise: Query for PNG files\n",
        "# webpage = \"covid19.govt.nz/assets/\"\n",
        "\n",
        "# df_captures = want.query_cdx_index(webpage, filter=\"mimetype:image/png\", matchType=\"prefix\")\n",
        "# df_captures[\"original_file_name\"] = df_captures[\"urlkey\"].str.split(\"/\").str[-1]\n",
        "# df_captures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3bXp5P3mQiX"
      },
      "source": [
        "## 3. Working with WARC Files\n",
        "\n",
        "WARC (Web ARChive) files are the standard format for storing web archives. They contain the actual content of archived web pages along with metadata. In this section, we'll explore how to access and extract data from WARC files in the NLNZ collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATZNKUoGlqre",
        "outputId": "228dc67b-5002-4a25-d9e9-3bc2cd2d1ef2"
      },
      "outputs": [],
      "source": [
        "# Define S3 bucket and folder containing the archive data\n",
        "bucket_name = \"ndha-public-data-ap-southeast-2\"\n",
        "folder_prefix = \"iPRES-2025\"\n",
        "\n",
        "# List available files in the S3 bucket\n",
        "want.list_s3_files(bucket_name, folder_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding CDX Files\n",
        "\n",
        "CDX (Capture inDeX) files serve as indexes for WARC files, making it easier to locate specific content. They follow a standardized format described in the [CDX documentation](https://iipc.github.io/warc-specifications/specifications/cdx-format/cdx-2015/).\n",
        "\n",
        "The standard 11-field CDX format includes:\n",
        "\n",
        "1. **N**: Normalized/massaged URL\n",
        "2. **b**: Capture date (timestamp)\n",
        "3. **a**: Original URL\n",
        "4. **m**: MIME type of the document\n",
        "5. **s**: HTTP response code\n",
        "6. **k**: Content checksum\n",
        "7. **r**: Redirect URL\n",
        "8. **M**: Meta tags\n",
        "9. **S**: Compressed record size\n",
        "10. **V**: Compressed payload offset\n",
        "11. **g**: Source WARC filename\n",
        "\n",
        "Let's load a CDX file and examine its structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a CDX file into a pandas DataFrame\n",
        "object_key = 'iPRES-2025/sample-data/covid19.govt.nz/2021-08-10_IE75130285/IE75130285.cdx'\n",
        "df = pd.read_csv(f\"s3://{bucket_name}/{object_key}\", sep=\" \", skiprows=1)\n",
        "\n",
        "# Assign column names according to the CDX standard\n",
        "df.columns = ['N', 'b', 'a', 'm', 's', 'k', 'r', 'M', 'S', 'V', 'g']\n",
        "\n",
        "# Display the first few rows\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Content from WARC Files\n",
        "\n",
        "Using the information from the CDX file (particularly the filename and offset), we can extract specific content from WARC files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBzSWb6TmT-p",
        "outputId": "6666477e-311e-4410-cc16-8132ebbb94fa"
      },
      "outputs": [],
      "source": [
        "# Extract HTML payload from a WARC file using a specific offset\n",
        "html_payload = want.extract_payload(\n",
        "    \"s3://ndha-public-data-ap-southeast-2/iPRES-2025/sample-data/covid19.govt.nz/2021-08-10_IE75130285/FL75130287_NLNZ-20210809041626170-00000-22439~kaiwae-z4~8443.warc.gz\",\n",
        "    offset=2593631\n",
        ")\n",
        "html_payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Processing and Analyzing Web Archive Content\n",
        "\n",
        "Once we've extracted content from WARC files, we can process and analyze it using various tools. For HTML content, BeautifulSoup is particularly useful for parsing and extracting text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse the HTML payload using BeautifulSoup\n",
        "soup = BeautifulSoup(html_payload, \"html.parser\")\n",
        "\n",
        "# Extract text from all paragraph elements\n",
        "paragraphs = [p.get_text(\" \", strip=True) for p in soup.find_all(\"p\")]\n",
        "\n",
        "# Print each paragraph\n",
        "for para in paragraphs:\n",
        "    print(para)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the Toolkit's Built-in Functions\n",
        "\n",
        "The NLNZ Web Archive Toolkit provides convenience functions that combine these steps. For example, `extract_content_html()` extracts text content from HTML payloads:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of using the toolkit's built-in functions\n",
        "# Note: This is a reference example and may not run as-is without proper context\n",
        "\n",
        "# Define a helper function to find WARC files (similar to what we'll use in later notebooks)\n",
        "bucket_name = \"ndha-public-data-ap-southeast-2\"\n",
        "folder_prefix = \"iPRES-2025/sample-data/covid19.govt.nz/\"\n",
        "all_files = want.list_s3_files(bucket_name, folder_prefix)\n",
        "\n",
        "def find_warc_file_path(warc_file):\n",
        "    \"\"\"Find the full S3 path for a given WARC filename.\n",
        "    \n",
        "    Args:\n",
        "        warc_file (str): The WARC filename to search for\n",
        "        \n",
        "    Returns:\n",
        "        str: Full S3 path if found, None otherwise\n",
        "    \"\"\"\n",
        "    for s3_file in all_files:  # all_files would be defined in actual usage\n",
        "        if warc_file in s3_file:\n",
        "            warc_file_path = f\"s3://{bucket_name}/{s3_file}\"\n",
        "            return warc_file_path\n",
        "    return None\n",
        "\n",
        "# Example usage of extract_content_html (reference only)\n",
        "warc_file = \"FL75130287_NLNZ-20210809041626170-00000-22439~kaiwae-z4~8443.warc.gz\"\n",
        "warc_offset = 2593631\n",
        "\n",
        "html_payload = want.extract_payload(find_warc_file_path(warc_file), warc_offset)\n",
        "content = want.extract_content_html(html_payload)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "This notebook has introduced the fundamental methods for accessing and working with web archives from the National Library of New Zealand:\n",
        "\n",
        "1. **Memento Protocol** - For standardized access to archived web content\n",
        "2. **CDX API** - For querying and filtering archive metadata\n",
        "3. **WARC Files** - For direct access to archived content\n",
        "4. **Content Extraction** - For processing and analyzing archived web pages\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "In the following notebooks, we'll build on these foundations to:\n",
        "\n",
        "- Explore and analyze web archive data in more depth\n",
        "- Track changes in websites over time\n",
        "- Extract and analyze textual content at scale\n",
        "- Build advanced applications using web archive data\n",
        "\n",
        "These techniques provide powerful tools for researchers, historians, and data scientists working with web archives."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
